{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relavent libraries and packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from BinaryConnect import BinaryConnectCNN_SVHN\n",
    "from BinaryConnect import custom_train_cnn\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "def load_svhn_data_online(url):\n",
    "    \"\"\" Load SVHN dataset from a URL \"\"\"\n",
    "    # Download and load the .mat file\n",
    "    response = urllib.request.urlopen(url)\n",
    "    content = response.read()\n",
    "    data = scipy.io.loadmat(io.BytesIO(content))\n",
    "    images = np.transpose(data['X'], [3, 0, 1, 2])\n",
    "    labels = data['y'].flatten()\n",
    "    labels[labels == 10] = 0  # Replace label 10 with 0\n",
    "    return images, labels\n",
    "\n",
    "# URLs to the SVHN dataset\n",
    "train_url = 'http://ufldl.stanford.edu/housenumbers/train_32x32.mat'\n",
    "test_url = 'http://ufldl.stanford.edu/housenumbers/test_32x32.mat'\n",
    "\n",
    "# Load the training and test data\n",
    "x_train, y_train = load_svhn_data_online(train_url)\n",
    "x_test, y_test = load_svhn_data_online(test_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\envs\\envTF210\\lib\\site-packages\\keras\\preprocessing\\image.py:1446: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Convert to float32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Compute the global mean and standard deviation\n",
    "global_mean = np.mean(x_train, axis=(0, 1, 2))\n",
    "global_std = np.std(x_train, axis=(0, 1, 2))\n",
    "\n",
    "# Apply global contrast normalization\n",
    "x_train = (x_train - global_mean) / (global_std + 1e-7)\n",
    "x_test = (x_test - global_mean) / (global_std + 1e-7)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = 10  # Adjust based on the dataset's specifics\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# ZCA Whitening\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "datagen.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#ensure using GPU to train the model to reduce training speed\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "Epoch 1/500, Train Loss: 2.4937117099761963, Train Accuracy: 13.773282051086426, Val Loss: 2.479660987854004, Val Accuracy: 12.491467475891113\n",
      "Epoch 2/500\n",
      "Epoch 2/500, Train Loss: 2.3688371181488037, Train Accuracy: 14.97148609161377, Val Loss: 2.435250759124756, Val Accuracy: 14.716723442077637\n",
      "Epoch 3/500\n",
      "Epoch 3/500, Train Loss: 2.3361258506774902, Train Accuracy: 15.858763694763184, Val Loss: 2.477688789367676, Val Accuracy: 11.549488067626953\n",
      "Epoch 4/500\n",
      "Epoch 4/500, Train Loss: 2.3124709129333496, Train Accuracy: 16.365346908569336, Val Loss: 2.387118339538574, Val Accuracy: 16.368600845336914\n",
      "Epoch 5/500\n",
      "Epoch 5/500, Train Loss: 2.2951204776763916, Train Accuracy: 16.6868896484375, Val Loss: 2.3452792167663574, Val Accuracy: 15.631400108337402\n",
      "Epoch 6/500\n",
      "Epoch 6/500, Train Loss: 2.2822372913360596, Train Accuracy: 17.29205894470215, Val Loss: 2.32820200920105, Val Accuracy: 16.600683212280273\n",
      "Epoch 7/500\n",
      "Epoch 7/500, Train Loss: 2.268902063369751, Train Accuracy: 17.643936157226562, Val Loss: 2.3094348907470703, Val Accuracy: 17.706485748291016\n",
      "Epoch 8/500\n",
      "Epoch 8/500, Train Loss: 2.2612881660461426, Train Accuracy: 17.957895278930664, Val Loss: 2.3117165565490723, Val Accuracy: 16.081911087036133\n",
      "Epoch 9/500\n",
      "Epoch 9/500, Train Loss: 2.25616717338562, Train Accuracy: 18.06406593322754, Val Loss: 2.291476011276245, Val Accuracy: 16.969282150268555\n",
      "Epoch 10/500\n",
      "Epoch 10/500, Train Loss: 2.2493107318878174, Train Accuracy: 18.341625213623047, Val Loss: 2.2823400497436523, Val Accuracy: 16.136518478393555\n",
      "Epoch 11/500\n",
      "Epoch 11/500, Train Loss: 2.246004819869995, Train Accuracy: 18.444761276245117, Val Loss: 2.271794319152832, Val Accuracy: 17.61092185974121\n",
      "Epoch 12/500\n",
      "Epoch 12/500, Train Loss: 2.241459608078003, Train Accuracy: 18.597949981689453, Val Loss: 2.2762832641601562, Val Accuracy: 17.733787536621094\n",
      "Epoch 13/500\n",
      "Epoch 13/500, Train Loss: 2.237342596054077, Train Accuracy: 18.704118728637695, Val Loss: 2.274406671524048, Val Accuracy: 17.679180145263672\n",
      "Epoch 14/500\n",
      "Epoch 14/500, Train Loss: 2.2330729961395264, Train Accuracy: 18.713218688964844, Val Loss: 2.2613444328308105, Val Accuracy: 17.91126251220703\n",
      "Epoch 15/500\n",
      "Epoch 15/500, Train Loss: 2.2267775535583496, Train Accuracy: 18.773887634277344, Val Loss: 2.2591216564178467, Val Accuracy: 18.034130096435547\n",
      "Epoch 16/500\n",
      "Epoch 16/500, Train Loss: 2.2222797870635986, Train Accuracy: 18.946794509887695, Val Loss: 2.2518362998962402, Val Accuracy: 17.733787536621094\n",
      "Epoch 17/500\n",
      "Epoch 17/500, Train Loss: 2.2162833213806152, Train Accuracy: 18.851240158081055, Val Loss: 2.2484474182128906, Val Accuracy: 17.81570053100586\n",
      "Epoch 18/500\n",
      "Epoch 18/500, Train Loss: 2.210139036178589, Train Accuracy: 18.87095832824707, Val Loss: 2.241605043411255, Val Accuracy: 18.10239028930664\n",
      "Epoch 19/500\n",
      "Epoch 19/500, Train Loss: 2.206144094467163, Train Accuracy: 18.977127075195312, Val Loss: 2.2398221492767334, Val Accuracy: 18.566553115844727\n",
      "Epoch 20/500\n",
      "Epoch 20/500, Train Loss: 2.202803134918213, Train Accuracy: 18.97409439086914, Val Loss: 2.2339420318603516, Val Accuracy: 18.361774444580078\n",
      "Epoch 21/500\n",
      "Epoch 21/500, Train Loss: 2.1998555660247803, Train Accuracy: 19.01807975769043, Val Loss: 2.225080728530884, Val Accuracy: 18.15699577331543\n",
      "Epoch 22/500\n",
      "Epoch 22/500, Train Loss: 2.196647882461548, Train Accuracy: 19.245586395263672, Val Loss: 2.2196969985961914, Val Accuracy: 18.88054656982422\n",
      "Epoch 23/500\n",
      "Epoch 23/500, Train Loss: 2.1934726238250732, Train Accuracy: 19.06964874267578, Val Loss: 2.2197086811065674, Val Accuracy: 18.812286376953125\n",
      "Epoch 24/500\n",
      "Epoch 24/500, Train Loss: 2.1913211345672607, Train Accuracy: 19.32445526123047, Val Loss: 2.2187674045562744, Val Accuracy: 19.276451110839844\n",
      "Epoch 25/500\n",
      "Epoch 25/500, Train Loss: 2.1891238689422607, Train Accuracy: 19.568645477294922, Val Loss: 2.2080907821655273, Val Accuracy: 19.098976135253906\n",
      "Epoch 26/500\n",
      "Epoch 26/500, Train Loss: 2.1846001148223877, Train Accuracy: 19.879573822021484, Val Loss: 2.2060556411743164, Val Accuracy: 19.20819091796875\n",
      "Epoch 27/500\n",
      "Epoch 27/500, Train Loss: 2.181140422821045, Train Accuracy: 20.025177001953125, Val Loss: 2.205641031265259, Val Accuracy: 19.645051956176758\n",
      "Epoch 28/500\n",
      "Epoch 28/500, Train Loss: 2.175267457962036, Train Accuracy: 20.61821174621582, Val Loss: 2.2022106647491455, Val Accuracy: 19.317405700683594\n",
      "Epoch 29/500\n",
      "Epoch 29/500, Train Loss: 2.164644241333008, Train Accuracy: 20.971607208251953, Val Loss: 2.2030951976776123, Val Accuracy: 19.604095458984375\n",
      "Epoch 30/500\n",
      "Epoch 30/500, Train Loss: 2.1513094902038574, Train Accuracy: 21.24916648864746, Val Loss: 2.1974539756774902, Val Accuracy: 19.42662239074707\n",
      "Epoch 31/500\n",
      "Epoch 31/500, Train Loss: 2.1427581310272217, Train Accuracy: 21.752716064453125, Val Loss: 2.1934211254119873, Val Accuracy: 19.590442657470703\n",
      "Epoch 32/500\n",
      "Epoch 32/500, Train Loss: 2.131082773208618, Train Accuracy: 22.336650848388672, Val Loss: 2.1926376819610596, Val Accuracy: 19.4129695892334\n",
      "Epoch 33/500\n",
      "Epoch 33/500, Train Loss: 2.1160573959350586, Train Accuracy: 23.36953353881836, Val Loss: 2.1901912689208984, Val Accuracy: 19.918088912963867\n",
      "Epoch 34/500\n",
      "Epoch 34/500, Train Loss: 2.1043219566345215, Train Accuracy: 23.845779418945312, Val Loss: 2.1834747791290283, Val Accuracy: 19.95904541015625\n",
      "Epoch 35/500\n",
      "Epoch 35/500, Train Loss: 2.0866124629974365, Train Accuracy: 24.757326126098633, Val Loss: 2.1779894828796387, Val Accuracy: 20.109214782714844\n",
      "Epoch 36/500\n",
      "Epoch 36/500, Train Loss: 2.0731892585754395, Train Accuracy: 25.409513473510742, Val Loss: 2.16961407661438, Val Accuracy: 20.709897994995117\n",
      "Epoch 37/500\n",
      "Epoch 37/500, Train Loss: 2.057626485824585, Train Accuracy: 26.176971435546875, Val Loss: 2.1586973667144775, Val Accuracy: 21.010238647460938\n",
      "Epoch 38/500\n",
      "Epoch 38/500, Train Loss: 2.040459632873535, Train Accuracy: 26.956562042236328, Val Loss: 2.1505672931671143, Val Accuracy: 21.733787536621094\n",
      "Epoch 39/500\n",
      "Epoch 39/500, Train Loss: 2.023237466812134, Train Accuracy: 27.53746223449707, Val Loss: 2.141552448272705, Val Accuracy: 22.11604118347168\n",
      "Epoch 40/500\n",
      "Epoch 40/500, Train Loss: 2.007838249206543, Train Accuracy: 28.389856338500977, Val Loss: 2.1331872940063477, Val Accuracy: 23.0034122467041\n",
      "Epoch 41/500\n",
      "Epoch 41/500, Train Loss: 1.9855149984359741, Train Accuracy: 29.3120174407959, Val Loss: 2.124303102493286, Val Accuracy: 23.72696304321289\n",
      "Epoch 42/500\n",
      "Epoch 42/500, Train Loss: 1.9595203399658203, Train Accuracy: 30.54662322998047, Val Loss: 2.1052823066711426, Val Accuracy: 24.55972671508789\n",
      "Epoch 43/500\n",
      "Epoch 43/500, Train Loss: 1.9197582006454468, Train Accuracy: 32.1922607421875, Val Loss: 2.0807790756225586, Val Accuracy: 25.174060821533203\n",
      "Epoch 44/500\n",
      "Epoch 44/500, Train Loss: 1.8602185249328613, Train Accuracy: 34.89200973510742, Val Loss: 2.027833938598633, Val Accuracy: 28.737201690673828\n",
      "Epoch 45/500\n",
      "Epoch 45/500, Train Loss: 1.7372617721557617, Train Accuracy: 39.33749771118164, Val Loss: 1.8999028205871582, Val Accuracy: 34.04778289794922\n",
      "Epoch 46/500\n",
      "Epoch 46/500, Train Loss: 1.6030737161636353, Train Accuracy: 44.33810806274414, Val Loss: 1.7902425527572632, Val Accuracy: 38.00682830810547\n",
      "Epoch 47/500\n",
      "Epoch 47/500, Train Loss: 1.4866704940795898, Train Accuracy: 48.93071746826172, Val Loss: 1.7053414583206177, Val Accuracy: 41.33788299560547\n",
      "Epoch 48/500\n",
      "Epoch 48/500, Train Loss: 1.3951071500778198, Train Accuracy: 52.59054946899414, Val Loss: 1.657815933227539, Val Accuracy: 43.86347961425781\n",
      "Epoch 49/500\n",
      "Epoch 49/500, Train Loss: 1.318725347518921, Train Accuracy: 55.36916732788086, Val Loss: 1.6055809259414673, Val Accuracy: 45.665531158447266\n",
      "Epoch 50/500\n",
      "Epoch 50/500, Train Loss: 1.2492865324020386, Train Accuracy: 57.91118240356445, Val Loss: 1.5825238227844238, Val Accuracy: 46.88054656982422\n",
      "Epoch 51/500\n",
      "Epoch 51/500, Train Loss: 1.1879584789276123, Train Accuracy: 60.39252471923828, Val Loss: 1.5553137063980103, Val Accuracy: 47.41297149658203\n",
      "Epoch 52/500\n",
      "Epoch 52/500, Train Loss: 1.1373651027679443, Train Accuracy: 62.35818862915039, Val Loss: 1.5088084936141968, Val Accuracy: 49.10580062866211\n",
      "Epoch 53/500\n",
      "Epoch 53/500, Train Loss: 1.0894100666046143, Train Accuracy: 64.29654693603516, Val Loss: 1.522546410560608, Val Accuracy: 48.0819091796875\n",
      "Epoch 54/500\n",
      "Epoch 54/500, Train Loss: 1.0495820045471191, Train Accuracy: 65.65855407714844, Val Loss: 1.5155375003814697, Val Accuracy: 48.01365280151367\n",
      "Epoch 55/500\n",
      "Epoch 55/500, Train Loss: 1.0090564489364624, Train Accuracy: 66.89164733886719, Val Loss: 1.5226693153381348, Val Accuracy: 46.853240966796875\n",
      "Epoch 56/500\n",
      "Epoch 56/500, Train Loss: 0.9731057286262512, Train Accuracy: 68.29460906982422, Val Loss: 1.4998321533203125, Val Accuracy: 47.01706314086914\n",
      "Epoch 57/500\n",
      "Epoch 57/500, Train Loss: 0.9337416887283325, Train Accuracy: 69.42152404785156, Val Loss: 1.522231936454773, Val Accuracy: 45.501705169677734\n",
      "Epoch 58/500\n",
      "Epoch 58/500, Train Loss: 0.8947258591651917, Train Accuracy: 70.8017349243164, Val Loss: 1.5192381143569946, Val Accuracy: 45.2423210144043\n",
      "Epoch 59/500\n",
      "Epoch 59/500, Train Loss: 0.85402512550354, Train Accuracy: 72.29570007324219, Val Loss: 1.529650092124939, Val Accuracy: 45.556312561035156\n",
      "Epoch 60/500\n",
      "Epoch 60/500, Train Loss: 0.8180037140846252, Train Accuracy: 73.61978912353516, Val Loss: 1.5059975385665894, Val Accuracy: 47.71331024169922\n",
      "Epoch 61/500\n",
      "Epoch 61/500, Train Loss: 0.7802682518959045, Train Accuracy: 74.84074401855469, Val Loss: 1.4968374967575073, Val Accuracy: 47.80887222290039\n",
      "Epoch 62/500\n",
      "Epoch 62/500, Train Loss: 0.7470930814743042, Train Accuracy: 75.9464340209961, Val Loss: 1.359690546989441, Val Accuracy: 53.21501541137695\n",
      "Epoch 63/500\n",
      "Epoch 63/500, Train Loss: 0.7136656045913696, Train Accuracy: 77.09913635253906, Val Loss: 1.3247730731964111, Val Accuracy: 54.580204010009766\n",
      "Epoch 64/500\n",
      "Epoch 64/500, Train Loss: 0.6811226606369019, Train Accuracy: 78.25032043457031, Val Loss: 1.1873116493225098, Val Accuracy: 59.686004638671875\n",
      "Epoch 65/500\n",
      "Epoch 65/500, Train Loss: 0.6475512385368347, Train Accuracy: 79.45762634277344, Val Loss: 1.1455581188201904, Val Accuracy: 62.539249420166016\n",
      "Epoch 66/500\n",
      "Epoch 66/500, Train Loss: 0.6172361969947815, Train Accuracy: 80.36309814453125, Val Loss: 1.1238749027252197, Val Accuracy: 62.33447265625\n",
      "Epoch 67/500\n",
      "Epoch 67/500, Train Loss: 0.5897555947303772, Train Accuracy: 81.4399642944336, Val Loss: 1.0513958930969238, Val Accuracy: 65.01023864746094\n",
      "Epoch 68/500\n",
      "Epoch 68/500, Train Loss: 0.5686966180801392, Train Accuracy: 81.98446655273438, Val Loss: 1.0349538326263428, Val Accuracy: 64.9010238647461\n",
      "Epoch 69/500\n",
      "Epoch 69/500, Train Loss: 0.5455255508422852, Train Accuracy: 82.73979187011719, Val Loss: 0.9913473725318909, Val Accuracy: 67.59044647216797\n",
      "Epoch 70/500\n",
      "Epoch 70/500, Train Loss: 0.5282042026519775, Train Accuracy: 83.45568084716797, Val Loss: 0.9847190380096436, Val Accuracy: 67.3447036743164\n",
      "Epoch 71/500\n",
      "Epoch 71/500, Train Loss: 0.5125082731246948, Train Accuracy: 84.02597045898438, Val Loss: 0.9553868770599365, Val Accuracy: 68.13652038574219\n",
      "Epoch 72/500\n",
      "Epoch 72/500, Train Loss: 0.4962944984436035, Train Accuracy: 84.46126556396484, Val Loss: 0.9006066918373108, Val Accuracy: 71.64505004882812\n",
      "Epoch 73/500\n",
      "Epoch 73/500, Train Loss: 0.47951406240463257, Train Accuracy: 84.958740234375, Val Loss: 0.8992412090301514, Val Accuracy: 70.6484603881836\n",
      "Epoch 74/500\n",
      "Epoch 74/500, Train Loss: 0.46961525082588196, Train Accuracy: 85.45925903320312, Val Loss: 0.8868738412857056, Val Accuracy: 71.50852966308594\n",
      "Epoch 75/500\n"
     ]
    }
   ],
   "source": [
    "#Trainingparameters\n",
    "batch_size = 50\n",
    "epochs = 500  # Reduced for faster training on subset\n",
    "validation_split = 0.1\n",
    "early_stopping_patience = 40\n",
    "\n",
    "\n",
    "# Initialize lists to store metrics for plotting\n",
    "stochastic_metrics = []\n",
    "deterministic_metrics = []\n",
    "\n",
    "# Train models with both deterministic and stochastic binarization\n",
    "for deterministic in [False, True]:\n",
    "    test_errors = []\n",
    "    train_times = []\n",
    "    trained_epochs = []\n",
    "\n",
    "    # Create and compile the model\n",
    "    model = BinaryConnectCNN_SVHN(deterministic)\n",
    "    model.compile(\n",
    "        optimizer='Adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Split data into training and validation sets\n",
    "    val_size = int(len(x_train) * validation_split)\n",
    "    x_val, y_val = x_train[-val_size:], y_train[-val_size:]\n",
    "    x_train_subset, y_train_subset = x_train[:-val_size], y_train[:-val_size]\n",
    "\n",
    "    # Start timing model training\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train the model using custom train function\n",
    "    train_losses, val_accuracies = custom_train_cnn(model, x_train_subset, y_train_subset, x_val, y_val, epochs, batch_size, early_stopping_patience)\n",
    "\n",
    "    # Store the training metrics for plotting\n",
    "    history_dict = {\n",
    "        'loss': train_losses,\n",
    "        'val_accuracy': val_accuracies\n",
    "    }\n",
    "\n",
    "    if deterministic:\n",
    "        deterministic_metrics.append(history_dict)\n",
    "    else:\n",
    "        stochastic_metrics.append(history_dict)\n",
    "\n",
    "    # Record training time and epochs\n",
    "    train_time = time.time() - start_time\n",
    "    train_times.append(train_time)\n",
    "    trained_epochs.append(epochs)  # Since custom_train doesn't return history\n",
    "\n",
    "    # Evaluate model on test set\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "    test_errors.append(1 - test_accuracy)\n",
    "\n",
    "    # Store metrics\n",
    "\n",
    "    print(\n",
    "        f\"Deterministic Binarization: {deterministic}\\n\"\n",
    "        f\"Average Test Error: {np.mean(test_errors)} +/- {np.std(test_errors)}\\n\"\n",
    "        f\"Average Training Time: {np.mean(train_times)} seconds\\n\"\n",
    "        f\"Average Number of Epochs: {np.mean(trained_epochs)}\"\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plotting\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Plot for stochastic binarization\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m history \u001b[38;5;129;01min\u001b[39;00m stochastic_metrics:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot for stochastic binarization\n",
    "for history in stochastic_metrics:\n",
    "    plt.plot(history['loss'], 'b--')  # Training loss\n",
    "    plt.plot(history['val_accuracy'], 'b')  # Validation accuracy\n",
    "\n",
    "# Plot for deterministic binarization\n",
    "for history in deterministic_metrics:\n",
    "    plt.plot(history['loss'], 'g--')  # Training loss\n",
    "    plt.plot(history['val_accuracy'], 'g')  # Validation accuracy\n",
    "\n",
    "plt.title('Training Curves on SVHN')\n",
    "plt.xlabel('Number of Epochs Trained')\n",
    "plt.ylabel('Validation Loss/ Accuracy')\n",
    "plt.legend(['Stochastic Train Loss', 'Stochastic Val Accuracy',\n",
    "            'Deterministic Train Loss', 'Deterministic Val Accuracy'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envTF210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
